{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "346e58f1",
   "metadata": {},
   "source": [
    "# Feature Selection - Stress Level Prediction\n",
    "\n",
    "This notebook performs feature selection to identify the most important features for stress level prediction.\n",
    "\n",
    "## Objectives:\n",
    "1. Load cleaned dataset\n",
    "2. Apply correlation-based feature selection\n",
    "3. Univariate feature selection\n",
    "4. Recursive Feature Elimination (RFE)\n",
    "5. Feature importance analysis\n",
    "6. Compare different selection methods\n",
    "7. Select final feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f347a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from utils.config import *\n",
    "from features.feature_selector import FeatureSelector\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60188c21",
   "metadata": {},
   "source": [
    "## 1. Load Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c77b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned dataset\n",
    "try:\n",
    "    cleaned_data_path = PROCESSED_DATA_DIR / \"cleaned_stress_data.csv\"\n",
    "    df = pd.read_csv(cleaned_data_path)\n",
    "    print(f\"Loaded cleaned dataset from: {cleaned_data_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Cleaned dataset not found. Please run the data cleaning notebook first.\")\n",
    "    # Create sample data for demonstration\n",
    "    np.random.seed(42)\n",
    "    n_samples = 800\n",
    "    \n",
    "    # Create sample features (after cleaning/scaling)\n",
    "    sample_data = {\n",
    "        'heart_rate': np.random.normal(0, 1, n_samples),\n",
    "        'sleep_hours': np.random.normal(0, 1, n_samples),\n",
    "        'exercise_minutes': np.random.normal(0, 1, n_samples),\n",
    "        'caffeine_intake': np.random.normal(0, 1, n_samples),\n",
    "        'work_hours': np.random.normal(0, 1, n_samples),\n",
    "        'age': np.random.normal(0, 1, n_samples),\n",
    "        'bmi': np.random.normal(0, 1, n_samples),\n",
    "        'blood_pressure_sys': np.random.normal(0, 1, n_samples),\n",
    "        'blood_pressure_dia': np.random.normal(0, 1, n_samples),\n",
    "        'gender_Male': np.random.choice([0, 1], n_samples),\n",
    "        'stress_level': np.random.choice([0, 1, 2], n_samples, p=[0.3, 0.5, 0.2])  # Encoded target\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(sample_data)\n",
    "    # Make some features more correlated with target for realistic selection\n",
    "    df.loc[df['stress_level'] == 2, 'heart_rate'] += 1.5\n",
    "    df.loc[df['stress_level'] == 2, 'work_hours'] += 1.2\n",
    "    df.loc[df['stress_level'] == 0, 'sleep_hours'] += 1.0\n",
    "    \n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58adb1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "target_col = 'stress_level'\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Feature columns: {list(X.columns)}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57c762b",
   "metadata": {},
   "source": [
    "## 2. Initialize Feature Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ba132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature selector\n",
    "selector = FeatureSelector()\n",
    "\n",
    "# Store results from different methods\n",
    "selection_results = {}\n",
    "\n",
    "print(\"Feature selector initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6a85b7",
   "metadata": {},
   "source": [
    "## 3. Correlation-Based Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c2a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply correlation analysis to remove highly correlated features\n",
    "print(\"Applying correlation-based feature selection...\")\n",
    "\n",
    "df_corr_reduced = selector.correlation_analysis(df, target_col, threshold=0.8)\n",
    "X_corr = df_corr_reduced.drop(columns=[target_col])\n",
    "\n",
    "removed_by_correlation = set(X.columns) - set(X_corr.columns)\n",
    "\n",
    "print(f\"Original features: {len(X.columns)}\")\n",
    "print(f\"Features after correlation filtering: {len(X_corr.columns)}\")\n",
    "print(f\"Features removed: {removed_by_correlation}\")\n",
    "\n",
    "selection_results['correlation_based'] = {\n",
    "    'selected_features': list(X_corr.columns),\n",
    "    'n_features': len(X_corr.columns),\n",
    "    'removed_features': list(removed_by_correlation)\n",
    "}\n",
    "\n",
    "# Visualize correlation matrix of remaining features\n",
    "if len(X_corr.columns) > 1:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    corr_matrix = X_corr.corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, linewidths=0.5)\n",
    "    plt.title('Correlation Matrix After Correlation-Based Selection')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f645b",
   "metadata": {},
   "source": [
    "## 4. Univariate Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78da7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply univariate feature selection\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "print(\"Applying univariate feature selection...\")\n",
    "\n",
    "k_features = min(8, len(X.columns))  # Select top 8 features or all if less\n",
    "univariate_features = selector.univariate_selection(X, y, k=k_features, score_func=f_classif)\n",
    "\n",
    "selection_results['univariate'] = {\n",
    "    'selected_features': univariate_features,\n",
    "    'n_features': len(univariate_features),\n",
    "    'feature_scores': selector.feature_scores\n",
    "}\n",
    "\n",
    "print(f\"Selected {len(univariate_features)} features using univariate selection\")\n",
    "print(f\"Selected features: {univariate_features}\")\n",
    "\n",
    "# Visualize feature scores\n",
    "if selector.feature_scores:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    scores_df = pd.DataFrame(list(selector.feature_scores.items()), \n",
    "                           columns=['Feature', 'Score'])\n",
    "    scores_df = scores_df.sort_values('Score', ascending=True)\n",
    "    \n",
    "    plt.barh(scores_df['Feature'], scores_df['Score'])\n",
    "    plt.title('Univariate Feature Scores (F-test)')\n",
    "    plt.xlabel('F-Score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5017c4b",
   "metadata": {},
   "source": [
    "## 5. Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907351ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Recursive Feature Elimination\n",
    "print(\"Applying Recursive Feature Elimination...\")\n",
    "\n",
    "n_features_rfe = min(6, len(X.columns))  # Select top 6 features\n",
    "rfe_features = selector.recursive_feature_elimination(X, y, n_features=n_features_rfe)\n",
    "\n",
    "selection_results['rfe'] = {\n",
    "    'selected_features': rfe_features,\n",
    "    'n_features': len(rfe_features)\n",
    "}\n",
    "\n",
    "print(f\"Selected {len(rfe_features)} features using RFE\")\n",
    "print(f\"Selected features: {rfe_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a6a0d1",
   "metadata": {},
   "source": [
    "## 6. Feature Importance-Based Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871d1f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature importance-based selection\n",
    "print(\"Applying feature importance-based selection...\")\n",
    "\n",
    "importance_features = selector.feature_importance_selection(X, y, threshold=0.05)\n",
    "\n",
    "selection_results['importance_based'] = {\n",
    "    'selected_features': importance_features,\n",
    "    'n_features': len(importance_features),\n",
    "    'feature_scores': selector.feature_scores\n",
    "}\n",
    "\n",
    "print(f\"Selected {len(importance_features)} features using importance threshold\")\n",
    "print(f\"Selected features: {importance_features}\")\n",
    "\n",
    "# Visualize feature importance\n",
    "if selector.feature_scores:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    importance_df = pd.DataFrame(list(selector.feature_scores.items()), \n",
    "                               columns=['Feature', 'Importance'])\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=True)\n",
    "    \n",
    "    plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "    plt.title('Random Forest Feature Importance')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.axvline(x=0.05, color='red', linestyle='--', label='Threshold (0.05)')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f66bc3",
   "metadata": {},
   "source": [
    "## 7. Mutual Information-Based Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae84e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mutual information-based selection\n",
    "print(\"Applying mutual information-based selection...\")\n",
    "\n",
    "k_features_mi = min(7, len(X.columns))  # Select top 7 features\n",
    "mi_features = selector.mutual_information_selection(X, y, k=k_features_mi)\n",
    "\n",
    "selection_results['mutual_information'] = {\n",
    "    'selected_features': mi_features,\n",
    "    'n_features': len(mi_features),\n",
    "    'feature_scores': selector.feature_scores\n",
    "}\n",
    "\n",
    "print(f\"Selected {len(mi_features)} features using mutual information\")\n",
    "print(f\"Selected features: {mi_features}\")\n",
    "\n",
    "# Visualize mutual information scores\n",
    "if selector.feature_scores:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    mi_df = pd.DataFrame(list(selector.feature_scores.items()), \n",
    "                        columns=['Feature', 'MI_Score'])\n",
    "    mi_df = mi_df.sort_values('MI_Score', ascending=True)\n",
    "    \n",
    "    plt.barh(mi_df['Feature'], mi_df['MI_Score'])\n",
    "    plt.title('Mutual Information Scores')\n",
    "    plt.xlabel('Mutual Information Score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2c1645",
   "metadata": {},
   "source": [
    "## 8. Compare Selection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caded11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different selection methods\n",
    "print(\"FEATURE SELECTION COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for method, results in selection_results.items():\n",
    "    print(f\"\\n{method.upper().replace('_', ' ')}:\")\n",
    "    print(f\"  Features selected: {results['n_features']}\")\n",
    "    print(f\"  Selected features: {results['selected_features']}\")\n",
    "\n",
    "# Create a comparison matrix\n",
    "all_features = list(X.columns)\n",
    "comparison_df = pd.DataFrame(index=all_features)\n",
    "\n",
    "for method, results in selection_results.items():\n",
    "    comparison_df[method] = comparison_df.index.isin(results['selected_features']).astype(int)\n",
    "\n",
    "# Add a sum column to see how many methods selected each feature\n",
    "comparison_df['total_selections'] = comparison_df.sum(axis=1)\n",
    "comparison_df = comparison_df.sort_values('total_selections', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Selection Comparison Matrix:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Visualize the comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(comparison_df.drop('total_selections', axis=1).T, \n",
    "            annot=True, cmap='RdYlBu', cbar_kws={'label': 'Selected (1) / Not Selected (0)'})\n",
    "plt.title('Feature Selection Methods Comparison')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Selection Methods')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e0e94e",
   "metadata": {},
   "source": [
    "## 9. Consensus-Based Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e70ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features based on consensus (selected by multiple methods)\n",
    "min_votes = 2  # Feature must be selected by at least 2 methods\n",
    "\n",
    "consensus_features = comparison_df[comparison_df['total_selections'] >= min_votes].index.tolist()\n",
    "\n",
    "print(f\"Consensus-based feature selection (min votes: {min_votes}):\")\n",
    "print(f\"Selected {len(consensus_features)} features: {consensus_features}\")\n",
    "\n",
    "# Show which methods selected each consensus feature\n",
    "print(\"\\nConsensus features selection details:\")\n",
    "for feature in consensus_features:\n",
    "    selecting_methods = []\n",
    "    for method in selection_results.keys():\n",
    "        if comparison_df.loc[feature, method] == 1:\n",
    "            selecting_methods.append(method)\n",
    "    print(f\"  {feature}: selected by {selecting_methods} ({len(selecting_methods)} votes)\")\n",
    "\n",
    "# Add to results\n",
    "selection_results['consensus'] = {\n",
    "    'selected_features': consensus_features,\n",
    "    'n_features': len(consensus_features),\n",
    "    'min_votes': min_votes\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56af1dfd",
   "metadata": {},
   "source": [
    "## 10. Final Feature Set Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d435028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose final feature set (using consensus approach)\n",
    "final_features = consensus_features\n",
    "\n",
    "# If consensus gives too few features, fall back to importance-based selection\n",
    "if len(final_features) < 3:\n",
    "    print(\"Consensus selected too few features. Using importance-based selection.\")\n",
    "    final_features = selection_results['importance_based']['selected_features']\n",
    "\n",
    "print(f\"\\nFINAL FEATURE SET:\")\n",
    "print(f\"Selected {len(final_features)} features: {final_features}\")\n",
    "\n",
    "# Create final datasets\n",
    "X_final = X[final_features]\n",
    "y_final = y\n",
    "\n",
    "print(f\"\\nFinal feature matrix shape: {X_final.shape}\")\n",
    "print(f\"Final target vector shape: {y_final.shape}\")\n",
    "\n",
    "# Visualize final feature correlations with target\n",
    "final_df = pd.concat([X_final, y_final], axis=1)\n",
    "correlations_with_target = final_df.corr()[target_col].drop(target_col).sort_values(key=abs, ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "correlations_with_target.plot(kind='barh')\n",
    "plt.title('Final Features Correlation with Target Variable')\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelations with target:\")\n",
    "for feature, corr in correlations_with_target.items():\n",
    "    print(f\"  {feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad12790c",
   "metadata": {},
   "source": [
    "## 11. Save Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee46bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the selected features dataset\n",
    "selected_features_path = PROCESSED_DATA_DIR / \"selected_features.csv\"\n",
    "final_target_path = PROCESSED_DATA_DIR / \"final_target.csv\"\n",
    "final_dataset_path = PROCESSED_DATA_DIR / \"final_dataset.csv\"\n",
    "\n",
    "# Save individual components\n",
    "X_final.to_csv(selected_features_path, index=False)\n",
    "y_final.to_csv(final_target_path, index=False, header=['stress_level'])\n",
    "final_df.to_csv(final_dataset_path, index=False)\n",
    "\n",
    "print(f\"Selected features saved to: {selected_features_path}\")\n",
    "print(f\"Target variable saved to: {final_target_path}\")\n",
    "print(f\"Final dataset saved to: {final_dataset_path}\")\n",
    "\n",
    "# Save feature selection results\n",
    "import json\n",
    "\n",
    "selection_summary = {\n",
    "    'original_features': list(X.columns),\n",
    "    'n_original_features': len(X.columns),\n",
    "    'final_features': final_features,\n",
    "    'n_final_features': len(final_features),\n",
    "    'selection_methods_used': list(selection_results.keys()),\n",
    "    'detailed_results': {\n",
    "        method: {\n",
    "            'selected_features': results['selected_features'],\n",
    "            'n_features': results['n_features']\n",
    "        } for method, results in selection_results.items()\n",
    "    },\n",
    "    'feature_selection_strategy': 'consensus_based',\n",
    "    'correlations_with_target': correlations_with_target.to_dict()\n",
    "}\n",
    "\n",
    "selection_results_path = PROCESSED_DATA_DIR / \"feature_selection_results.json\"\n",
    "with open(selection_results_path, 'w') as f:\n",
    "    json.dump(selection_summary, f, indent=2, default=str)\n",
    "\n",
    "print(f\"Feature selection results saved to: {selection_results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6885eba",
   "metadata": {},
   "source": [
    "## 12. Feature Selection Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daff8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive feature selection summary\n",
    "print(\"FEATURE SELECTION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Original features: {len(X.columns)}\")\n",
    "print(f\"Final features: {len(final_features)}\")\n",
    "print(f\"Reduction: {len(X.columns) - len(final_features)} features ({((len(X.columns) - len(final_features))/len(X.columns)*100):.1f}%)\")\n",
    "\n",
    "print(f\"\\nSelected Features:\")\n",
    "for i, feature in enumerate(final_features, 1):\n",
    "    corr = correlations_with_target[feature]\n",
    "    print(f\"  {i:2d}. {feature:20s} (correlation: {corr:6.3f})\")\n",
    "\n",
    "print(f\"\\nFeature Selection Methods Applied:\")\n",
    "for method in selection_results.keys():\n",
    "    print(f\"  âœ“ {method.replace('_', ' ').title()}\")\n",
    "\n",
    "print(f\"\\nDataset is ready for model training!\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"1. Train-test split\")\n",
    "print(f\"2. Model training and comparison\")\n",
    "print(f\"3. Hyperparameter tuning\")\n",
    "print(f\"4. Model evaluation\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
